{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Stochastic Optimization Methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "An overview over the different types of optimization algorithms is given in the table below.\n",
    "\n",
    "Deterministic | Stochastic\n",
    ":------- | :-------\n",
    "Steepest Descent  | Monte Carlo\n",
    "Conjugate Gradient Method  | Simulated Annealing\n",
    "Modified Newton's Method | Evolutionary Algorithms     |\n",
    "Quasi-Newton's Method |\n",
    "Barrier/Penalty Methods |\n",
    "SLP, SQP |\n",
    "\n",
    "The stochastic optimization methods which are going to be shown within this notebook are Monte Carlo, Simulated Annealing, and Evolutionary Algorithms.\n",
    "All of the above belong to the class of global optimization algorithms which find a global optima of **any** given function."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "source": [
    "## Monte Carlo"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Simulated Annealing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Evolutionary Algorithms"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}